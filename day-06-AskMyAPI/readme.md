<div align="center">

# ğŸš€ Local API Explorer

Turn any OpenAPI / Swagger spec into a searchable naturalâ€‘language explorer. Upload a spec, embed endpoints, and ask questions like *"How do I create a user?"*.

</div>

## âœ¨ Current Features (Implemented)

- Upload OpenAPI / Swagger JSON (`/upload` FastAPI endpoint via Streamlit UI)
- Parse endpoints (path, method, summary, description, parameters)
- Generate embeddings (OpenAI if key present, otherwise local backend to be added; currently OpenAI only in `embedding_utils.py` fallback logic partially stubbed)
- Persist vector store with Chroma (`chroma_store/` folder)
- Semantic similarity search over endpoints (`/query`)
- Streamlit UI to index + search
- Health check endpoint (`/health`)

## ğŸ§­ Architecture

```
OpenAPI Spec â†’ Parse â†’ Build Documents â†’ Embed â†’ Chroma (persist)
													â†‘
User Query â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Embed â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Similarity Search â”€â”€â–º Ranked Endpoints â†’ UI
```

## ğŸ—‚ Project Structure (Actual)

```
day-06-AskMyAPI/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api.py               # FastAPI app (upload/query)
â”‚   â”œâ”€â”€ embedding_utils.py   # Parsing + embedding + Chroma persistence
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ readme.md
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py               # Streamlit UI
â”œâ”€â”€ requirements.txt         # Root dependency list (backend + frontend)
â”œâ”€â”€ .env.example             # Environment variable template
â””â”€â”€ readme.md                # This file
```

## âš™ï¸ Environment Variables

Copy `.env.example` to `.env` (optional):

| Variable | Purpose | Default |
|----------|---------|---------|
| `OPENAI_API_KEY` | Enables OpenAI embeddings | (none) |
| `EMBEDDING_MODEL` | Override model name | `text-embedding-3-small` (OpenAI) |
| `CHROMA_PERSIST_DIR` | Vector DB directory | `chroma_store` |
| `LOG_LEVEL` | Logging verbosity | `INFO` |

> Local (nonâ€‘OpenAI) embedding fallback placeholder exists; install sentence-transformers & add logic if needed.

## ğŸš€ Quick Start

### 1. Create & Activate Virtual Env (PowerShell)
```powershell
python -m venv .venv
.\.venv\Scripts\activate
```

### 2. Install Dependencies
```powershell
pip install -r requirements.txt
```

### 3. Run Backend (FastAPI)
```powershell
python -m backend.api  # or: uvicorn backend.api:app --reload
```
Visit: http://localhost:8000/docs

### 4. Run Frontend (Streamlit)
```powershell
streamlit run frontend/app.py
```

### 5. Use It
1. In Streamlit, upload your `openapi.json` file
2. Wait for indexing success message
3. Enter a natural language question
4. Expand results to view endpoint details

## ğŸ” API Endpoints

| Method | Path | Description |
|--------|------|-------------|
| `GET` | `/health` | Service status |
| `POST` | `/upload` | Multipart file upload (`file` field) to index spec |
| `POST` | `/query` | JSON body: `{ "query": str, "k": int }` returns ranked endpoints |

## ğŸ“¦ Internals

Parsing builds a normalized list of endpoints with joined textual representation used for embedding. Chroma stores embeddings persistently so repeated queries don't recompute them. The `/upload` endpoint currently recreates the store each time (simple MVP strategy). Incremental updates are a potential enhancement.

## âœ… MVP Status

| Capability | Status |
|------------|--------|
| Spec Upload | Done |
| Endpoint Parsing | Done |
| Embedding Generation | Done (OpenAI path) |
| Vector Store Persistence | Done (Chroma) |
| Semantic Search | Done |
| Streamlit UI | Done |
| Local Embedding Fallback | Partial (placeholder) |
| Try-it-out Request Builder | Planned |
